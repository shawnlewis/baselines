wandb_version: 1

# Example variables below. Uncomment (remove leading '# ') to use them, or just
# delete and create your own.

visualize:
  desc: Turn on visualization of rollouts
  value: True
difficulty:
  desc: Environment difficulty
  value: 2
init_pol_weight_stddev:
  value: 0.3
init_logstd:
  value: -1.5
action_bias:
  value: 0.5
action_repeat:
  value: 8
action_repeat_rand:
  value: True
time_penalty:
  value: 0.2
fall_smoothing_exp:
  desc: Reward-shaping. Fall smoothing exponent
  value: 2.0
fall_smoothing_max_penalty:
  desc: Reward-shaping. Fall smoothing max penalty
  value: 0
velocity_penalty_mult:
  desc: Reward-shaping. Velocity penalty multiplier
  value: 0
alive_bonus:
  desc: Alive bonus.
  value: 0.01
seed:
  desc: Run seed
  value: 0
max_timesteps:
  desc: Maximum number of simulation timesteps before exit
  value: 400000000
horizon:
  desc: Horizon parameter, number of timesteps per rollout batch.
  value: 512
clip_param:
  desc: PPO Clip parameter
  value: 0.2
entcoeff:
  desc: Penalty parameter. Paper says performs worse.
  value: 0.0
optim_epochs:
  desc: Number of epochs in Adam update
  value: 15
optim_batchsize:
  desc: Batch size for each Adam update (mult by num processes)
  value: 16
optim_stepsize:
  desc: Adam step size per update
  value: 0.0003
target_kl:
  desc: target KL
  value: 0.001
discount:
  desc: RL discount
  value: 0.99
lam:
  desc: What is this?
  value: 0.95
lr_schedule:
  desc: Anneal learning rate, either constant or linear
  value: target_kl
load_model:
  desc: Model checkpoint to start from
  value: False
hidden_layers:
  desc: Hidden layer widths
  value: [256, 128]
load_model:
  value: False
load_model:
  value: checkpoints/5rpdymbm-timepen/model-40.ckpt
